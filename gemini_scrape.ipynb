{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "    html:\n",
    "        embed-resources: true\n",
    "execute:\n",
    "  freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gtown/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: movies_chunk_133.json\n",
      "processing file: movies_chunk_125.json\n",
      "Attempt 1: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 2: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 3: Rate limit hit. Retrying in 10 seconds...\n",
      "Exceeded retry limit.\n",
      "No reponse from API\n",
      "processing file: movies_chunk_109.json\n",
      "Attempt 1: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 2: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 3: Rate limit hit. Retrying in 10 seconds...\n",
      "Exceeded retry limit.\n",
      "No reponse from API\n",
      "Attempt 1: Rate limit hit. Retrying in 10 seconds...\n",
      "processing file: movies_chunk_71.json\n",
      "Attempt 1: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 2: Rate limit hit. Retrying in 10 seconds...\n",
      "processing file: movies_chunk_26.json\n",
      "Attempt 1: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 1: Rate limit hit. Retrying in 10 seconds...\n",
      "Attempt 2: Rate limit hit. Retrying in 10 seconds...\n",
      "processing file: movies_chunk_30.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import chardet\n",
    "\n",
    "# Load API key\n",
    "with open('/Users/lizziehealy/.api-keys.json') as f:\n",
    "    keys = json.load(f)\n",
    "API_KEY = keys['gemapi']\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Helper function to chat with Gemini API\n",
    "def chat_with_gemini(prompt, retries=3, delay=10):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            model = genai.GenerativeModel(\"gemini-1.5-flash-8b-latest\")\n",
    "            response = model.generate_content(prompt)\n",
    "            # Extract the response content\n",
    "            answer = response.candidates[0].content.parts[0].text\n",
    "            return answer\n",
    "\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):  # Rate limit error\n",
    "                print(f\"Attempt {attempt + 1}: Rate limit hit. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return None\n",
    "    print(\"Exceeded retry limit.\")\n",
    "    return None\n",
    "\n",
    "# Updated function to clean and parse the response\n",
    "def parse_response(response):\n",
    "    try:\n",
    "        # Remove any common code block markers\n",
    "        cleaned_response = re.sub(r\"```json|```\", \"\", response).strip()\n",
    "\n",
    "        # Use regex to extract JSON-like content\n",
    "        json_match = re.search(r\"\\{.*\\}\", cleaned_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_content = json_match.group(0)\n",
    "            parsed_data = json.loads(json_content)\n",
    "            return parsed_data\n",
    "        else:\n",
    "            print(\"No JSON content found in the response.\")\n",
    "            return None\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "# Main function to process job postings\n",
    "def process_movies():\n",
    "    all_movies = []  # List to store cleaned job data\n",
    "    \n",
    "    for filename in os.listdir('Data'):\n",
    "        if not filename.endswith('.json'):\n",
    "            print(f\"Skipping non-JSON file: {filename}\")\n",
    "            continue\n",
    "        input_file = os.path.join('Data', filename)\n",
    "        print(f\"processing file: {filename}\")\n",
    "        \n",
    "        with open(input_file, 'r', encoding='Windows-1252') as file:\n",
    "            movie_data = json.load(file)\n",
    "            # movies = movie_data.get(\"Title\", [])\n",
    "\n",
    "            for index, movie in enumerate(movie_data):\n",
    "                if index >= 15:\n",
    "                    break\n",
    "                title = movie.get(\"Title\")\n",
    "                prompt = f\"\"\"\n",
    "                You are an expert in rating films. Can you please give me a score of how much\n",
    "                each film from this list: \"{title}\" fits into each of these categories. Please score from 0-1, where 0 is the \n",
    "                film does not fit the category at all and 1 is that the film perfectly fits the category \n",
    "                (the score don't have to add to 1 and the precision is 0.01). Base these results on your \n",
    "                understanding of the film from IMDb and google description of the film. DO NOT OUTPUT NAN - give \n",
    "                a score for each movie, for each genre. Please output these scores \n",
    "                for each film directly as a JSON response (ie like this: \n",
    "                [{{'Mission: Impossible 2': {{'action': 0.95, 'adventure': 0.9,}}}}]). \n",
    "                Here are the categories:\n",
    "\n",
    "                - action\n",
    "                - adventure\n",
    "                - animation\n",
    "                - art\n",
    "                - biography\n",
    "                - comedy\n",
    "                - crime\n",
    "                - dark comedy\n",
    "                - documentary\n",
    "                - drama\n",
    "                - epic\n",
    "                - family\n",
    "                - fantasy\n",
    "                - fiction\n",
    "                - history\n",
    "                - historical drama\n",
    "                - horror\n",
    "                - music\n",
    "                - musical\n",
    "                - mystery\n",
    "                - noir\n",
    "                - romance\n",
    "                - romantic comedy\n",
    "                - science fiction\n",
    "                - sport\n",
    "                - thriller\n",
    "                - war\n",
    "                - western\n",
    "                \"\"\"\n",
    "\n",
    "        # Get the response from Gemini API\n",
    "                response = chat_with_gemini(prompt)\n",
    "                if response:\n",
    "                    parsed_data = parse_response(response)\n",
    "                    if parsed_data:\n",
    "                        all_movies.append(parsed_data)\n",
    "                    else:\n",
    "                        print(f\"Failed to parse response\")\n",
    "                else:\n",
    "                    print(\"No reponse from API\")\n",
    "\n",
    "    return all_movies\n",
    "\n",
    "# Execute the job processing function and save to a DataFrame\n",
    "cleaned_movies = process_movies()\n",
    "print(cleaned_movies)\n",
    "if cleaned_movies:\n",
    "    flattened_data = []\n",
    "    for movie in cleaned_movies:\n",
    "        for film_name, genres in movie.items():\n",
    "            # Create a new dictionary with the film name and genres\n",
    "            flattened_entry = {'movie': film_name}\n",
    "            if isinstance(genres, dict):\n",
    "                flattened_entry.update(genres)  # Add genre scores to the dictionary\n",
    "            else:\n",
    "                print(f\"Unexpected data format for genres: {genres}\")\n",
    "            flattened_data.append(flattened_entry)\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "    print(df)\n",
    "    print(\"Checking for missing values in the DataFrame:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    output_path = \"cleaned_movies.csv\"\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No data to save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtown",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
